{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "orig_nbformat": 4,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit"
    },
    "interpreter": {
      "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
    },
    "colab": {
      "name": "raizen-analytics_data-engineering-test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJaCK3doCFk4"
      },
      "source": [
        "# Solution to Data Engineering Test\n",
        "\n",
        "*by github.com/albertotav*\n",
        "\n",
        "This is my particular attempt to solve to the Data Engineering Test created by Raízen Analytics, which can be found at github.com/raizen-analytics/data-engineering-test.\n",
        "\n",
        "It consists of a two stages approach. First, the underlying data from the two requested tables on the ANP pivot table (on vendas-combustiveis-m3.xls workbook) is extracted using a VBA Macro whose code can be found at github.com/albertotav/raizen-data-engineering-test/blob/main/raw_data/pivot_data_macro.bas. This method was chosen as its simplicity allow direct extraction of the wanted underlying data from the pivot table without having to convert it to other formats (other than enabling macros), using VBA’s Range.ShowDetail property and saving both resulting sheets as .csv files.\n",
        "\n",
        "The second stage divides into two possible solutions: \n",
        "\n",
        "A) A Jupyter notebook (raizen-analytics_data-engineering-test.ipynb), that read the raw csv files from stage one and exports it as refined data with the challenge required schema set that has been written with the intention of delivering easily replicable results using Google’s Colab platform and includes, as requested, a verify function that check if the refined data sum matches that of the raw data total sum column. This notebook intends to show how each step was developed and how it works.\n",
        "\n",
        "B) An Apache Airflow DAG. The pipeline reads the raw data from stage one, set the required schema and save into Parquet format as a single dataframe.\n",
        "\n",
        "More info at https://github.com/albertotav/raizen-data-engineering-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KsMZO7omoMe",
        "outputId": "91556b98-9a8e-4480-fd2e-0e507432674f"
      },
      "source": [
        "import urllib.request\n",
        "\n",
        "# Get raw csv from githbub folder in albertotav/raizen-data-engineering-test/tree/main/raw_data\n",
        "\n",
        "target_url = 'https://github.com/albertotav/raizen-data-engineering-test/blob/main/raw_data/diesel_by_uf_and_type.csv.gz?raw=true'\n",
        "filename = 'diesel_by_uf_and_type.csv.gz'\n",
        "\n",
        "urllib.request.urlretrieve(target_url, filename)\n",
        "\n",
        "target_url = 'https://github.com/albertotav/raizen-data-engineering-test/blob/main/raw_data/oil_derivative_fuels_by_uf_and_product.csv.gz?raw=true'\n",
        "filename = 'oil_derivative_fuels_by_uf_and_product.csv.gz'\n",
        "\n",
        "urllib.request.urlretrieve(target_url, filename)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('oil_derivative_fuels_by_uf_and_product.csv.gz',\n",
              " <http.client.HTTPMessage at 0x7fc92ee04910>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-g5HMpdGt6_o"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "\n",
        "# Creates dataframes with Pandas for both csv files. \n",
        "\n",
        "df_diesel_raw = pd.read_csv('diesel_by_uf_and_type.csv.gz',compression='gzip', encoding='iso-8859-1')\n",
        "df_oil_raw = pd.read_csv('oil_derivative_fuels_by_uf_and_product.csv.gz',compression='gzip', encoding='iso-8859-1')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqXKKbzRvq4O"
      },
      "source": [
        "def translate_setdate(df):\n",
        "  \"\"\"\n",
        "  Translate dataframe colums names to english and creates year_month datetype column.\n",
        "\n",
        "  :param pd.DataFrame df: diesel-by-uf-and-type.csv or oil-derivative-fuels-by-uf-and-product.csv derivate Pandas dataframe\n",
        "\n",
        "  :returns: DataFrame with processed data.\n",
        "  :rtype: pd.DataFrame\n",
        "  \"\"\"\n",
        "\n",
        "  df.columns = ['product','year','region','uf','unit', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec','TOTAL']\n",
        "\n",
        "  df = pd.melt(df, \n",
        "     id_vars=list(df.columns[0:5]), \n",
        "     value_vars=list(df.columns[5:-1]),\n",
        "     var_name='month',\n",
        "     value_name='volume')\n",
        "\n",
        "  df['year_month'] = df['year'].astype(str)+'-'+df['month']\n",
        "  df['year_month'] = pd.to_datetime(df['year_month'], format= '%Y-%b').dt.date\n",
        "\n",
        "  df = df[['year_month','uf','product','unit','volume']]\n",
        "  df['volume'].fillna(0, inplace=True) # Fills volume column NaNs with zero. Those are present in the months of 2020 not yet accounted for.\n",
        "\n",
        "  return df"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WClHsms1916M",
        "outputId": "fee1a1b7-b8af-463f-c9b9-e67898cd7318"
      },
      "source": [
        "# Creates Pandas df to be used with pyspark\n",
        "\n",
        "df_oil = translate_setdate(df_oil_raw)\n",
        "df_diesel = translate_setdate(df_diesel_raw)\n",
        "\n",
        "print('df_oil row count: ',len(df_oil.index))\n",
        "print('df_oil columns: ',list(df_oil.columns))\n",
        "print('\\ndf_diesel row count: ',len(df_diesel.index))\n",
        "print('df_diesel columns: ',list(df_diesel.columns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_oil row count:  54432\n",
            "df_oil columns:  ['year_month', 'uf', 'product', 'unit', 'volume']\n",
            "\n",
            "df_diesel row count:  12960\n",
            "df_diesel columns:  ['year_month', 'uf', 'product', 'unit', 'volume']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1kMDbfeRRKb"
      },
      "source": [
        "## Pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa4yojeQhwpO"
      },
      "source": [
        "#### Installing pyspark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbqmP2FELtb",
        "outputId": "9835e238-7fb3-4cee-b912-15819703e4de"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 67kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 20.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=dff0f0729d52f61fe4a464e0fd13ee1bc87531ee0882f6e6a15b334cc17cfe34\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCSTWVYKXc2j"
      },
      "source": [
        "#### Start pyspark session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ49AAivEQLq"
      },
      "source": [
        "from pyspark.sql.types import StructType, StructField, StringType, DateType, TimestampType, DoubleType\n",
        "from pyspark.sql.functions import lit, unix_timestamp\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Start Spark session\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        ".appName('Python-spark-session') \\\n",
        ".config('spark.sql.session.timeZone', 'America/Sao_Paulo') \\\n",
        ".getOrCreate()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYNUzpRVXsyC"
      },
      "source": [
        "#### Creates spark dataframes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORGEQg3AGV1g"
      },
      "source": [
        "import time\n",
        "\n",
        "# Defines schema as requested by the challenge\n",
        "\n",
        "schema = StructType([\n",
        "  StructField('year_month', DateType(), False),\n",
        "  StructField('uf', StringType(), False),\n",
        "  StructField('product', StringType(), False),\n",
        "  StructField('unit', StringType(), False),\n",
        "  StructField('volume', DoubleType(), True),\n",
        "  ])\n",
        "\n",
        "# Creates Spark Dataframes with required schema and timestamp column\n",
        "\n",
        "spark_df_oil = spark.createDataFrame(df_oil, schema=schema) \\\n",
        "  .withColumn('created_at', unix_timestamp(lit(datetime.datetime.fromtimestamp(time.time()) \\\n",
        "  .strftime('%Y-%m-%d %H:%M:%S')),'yyyy-MM-dd HH:mm:ss') \\\n",
        "  .cast(\"timestamp\")) \n",
        "\n",
        "spark_df_diesel = spark.createDataFrame(df_diesel, schema=schema) \\\n",
        "  .withColumn('created_at', unix_timestamp(lit(datetime.datetime.fromtimestamp(time.time()) \\\n",
        "  .strftime('%Y-%m-%d %H:%M:%S')),'yyyy-MM-dd HH:mm:ss') \\\n",
        "  .cast(\"timestamp\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swoa4Y8BWY3v"
      },
      "source": [
        "#### Verifying schema"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzI3b6tjHXXm",
        "outputId": "8c7dc543-ce7a-4453-c746-90188fffa0bd"
      },
      "source": [
        "print('spark_df_oil schema:')\n",
        "spark_df_oil.printSchema()\n",
        "\n",
        "print('spark_df_diesel schema:')\n",
        "spark_df_diesel.printSchema()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark_df_oil schema:\n",
            "root\n",
            " |-- year_month: date (nullable = false)\n",
            " |-- uf: string (nullable = false)\n",
            " |-- product: string (nullable = false)\n",
            " |-- unit: string (nullable = false)\n",
            " |-- volume: double (nullable = true)\n",
            " |-- created_at: timestamp (nullable = true)\n",
            "\n",
            "spark_df_diesel schema:\n",
            "root\n",
            " |-- year_month: date (nullable = false)\n",
            " |-- uf: string (nullable = false)\n",
            " |-- product: string (nullable = false)\n",
            " |-- unit: string (nullable = false)\n",
            " |-- volume: double (nullable = true)\n",
            " |-- created_at: timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhUkwN8tWfDa"
      },
      "source": [
        "#### Dataframe preview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia1J8tU8WQ0F",
        "outputId": "4bfe22bd-b4ef-48ac-892f-fa63d140a78d"
      },
      "source": [
        "spark_df_oil.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+---------------+----+------------------+-------------------+\n",
            "|year_month|                 uf|        product|unit|            volume|         created_at|\n",
            "+----------+-------------------+---------------+----+------------------+-------------------+\n",
            "|2000-01-01|           RONDÔNIA|GASOLINA C (m3)|  m3|          9563.263|2021-06-24 00:41:02|\n",
            "|2000-01-01|               ACRE|GASOLINA C (m3)|  m3|          3065.758|2021-06-24 00:41:02|\n",
            "|2000-01-01|           AMAZONAS|GASOLINA C (m3)|  m3|         17615.604|2021-06-24 00:41:02|\n",
            "|2000-01-01|            RORAIMA|GASOLINA C (m3)|  m3|            3259.3|2021-06-24 00:41:02|\n",
            "|2000-01-01|               PARÁ|GASOLINA C (m3)|  m3|         28830.479|2021-06-24 00:41:02|\n",
            "|2000-01-01|              AMAPÁ|GASOLINA C (m3)|  m3|           3456.35|2021-06-24 00:41:02|\n",
            "|2000-01-01|          TOCANTINS|GASOLINA C (m3)|  m3|          6961.518|2021-06-24 00:41:02|\n",
            "|2000-01-01|           MARANHÃO|GASOLINA C (m3)|  m3|          16751.08|2021-06-24 00:41:02|\n",
            "|2000-01-01|              PIAUÍ|GASOLINA C (m3)|  m3|            8452.2|2021-06-24 00:41:02|\n",
            "|2000-01-01|              CEARÁ|GASOLINA C (m3)|  m3|         38492.506|2021-06-24 00:41:02|\n",
            "|2000-01-01|RIO GRANDE DO NORTE|GASOLINA C (m3)|  m3|           19130.2|2021-06-24 00:41:02|\n",
            "|2000-01-01|            PARAÍBA|GASOLINA C (m3)|  m3|         20166.052|2021-06-24 00:41:02|\n",
            "|2000-01-01|         PERNAMBUCO|GASOLINA C (m3)|  m3|         51905.707|2021-06-24 00:41:02|\n",
            "|2000-01-01|            ALAGOAS|GASOLINA C (m3)|  m3|          14001.15|2021-06-24 00:41:02|\n",
            "|2000-01-01|            SERGIPE|GASOLINA C (m3)|  m3|12292.883999999998|2021-06-24 00:41:02|\n",
            "|2000-01-01|              BAHIA|GASOLINA C (m3)|  m3|         79545.219|2021-06-24 00:41:02|\n",
            "|2000-01-01|       MINAS GERAIS|GASOLINA C (m3)|  m3|182555.48100000003|2021-06-24 00:41:02|\n",
            "|2000-01-01|     ESPÍRITO SANTO|GASOLINA C (m3)|  m3|         43744.621|2021-06-24 00:41:02|\n",
            "|2000-01-01|     RIO DE JANEIRO|GASOLINA C (m3)|  m3|        152471.323|2021-06-24 00:41:02|\n",
            "|2000-01-01|          SÃO PAULO|GASOLINA C (m3)|  m3|        579928.009|2021-06-24 00:41:02|\n",
            "+----------+-------------------+---------------+----+------------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8OaqcpcHauH",
        "outputId": "5a83f295-359b-458d-b14a-ca1e1efdec92"
      },
      "source": [
        "spark_df_diesel.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-------------------+--------------------+----+-----------------+-------------------+\n",
            "|year_month|                 uf|             product|unit|           volume|         created_at|\n",
            "+----------+-------------------+--------------------+----+-----------------+-------------------+\n",
            "|2013-01-01|           RONDÔNIA|ÓLEO DIESEL S-10 ...|  m3|           3517.6|2021-06-24 00:41:03|\n",
            "|2013-01-01|               ACRE|ÓLEO DIESEL S-10 ...|  m3|            363.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|           AMAZONAS|ÓLEO DIESEL S-10 ...|  m3|         3190.585|2021-06-24 00:41:03|\n",
            "|2013-01-01|            RORAIMA|ÓLEO DIESEL S-10 ...|  m3|            795.4|2021-06-24 00:41:03|\n",
            "|2013-01-01|               PARÁ|ÓLEO DIESEL S-10 ...|  m3|          30137.8|2021-06-24 00:41:03|\n",
            "|2013-01-01|              AMAPÁ|ÓLEO DIESEL S-10 ...|  m3|            252.5|2021-06-24 00:41:03|\n",
            "|2013-01-01|          TOCANTINS|ÓLEO DIESEL S-10 ...|  m3|           6365.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|           MARANHÃO|ÓLEO DIESEL S-10 ...|  m3|          8896.45|2021-06-24 00:41:03|\n",
            "|2013-01-01|              PIAUÍ|ÓLEO DIESEL S-10 ...|  m3|           4048.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|              CEARÁ|ÓLEO DIESEL S-10 ...|  m3|56758.64599999999|2021-06-24 00:41:03|\n",
            "|2013-01-01|RIO GRANDE DO NORTE|ÓLEO DIESEL S-10 ...|  m3|           2722.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|            PARAÍBA|ÓLEO DIESEL S-10 ...|  m3|           2401.5|2021-06-24 00:41:03|\n",
            "|2013-01-01|         PERNAMBUCO|ÓLEO DIESEL S-10 ...|  m3|         94832.55|2021-06-24 00:41:03|\n",
            "|2013-01-01|            ALAGOAS|ÓLEO DIESEL S-10 ...|  m3|           4078.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|            SERGIPE|ÓLEO DIESEL S-10 ...|  m3|           4191.5|2021-06-24 00:41:03|\n",
            "|2013-01-01|              BAHIA|ÓLEO DIESEL S-10 ...|  m3|        25274.123|2021-06-24 00:41:03|\n",
            "|2013-01-01|       MINAS GERAIS|ÓLEO DIESEL S-10 ...|  m3|46251.40900000001|2021-06-24 00:41:03|\n",
            "|2013-01-01|     ESPÍRITO SANTO|ÓLEO DIESEL S-10 ...|  m3|           7078.0|2021-06-24 00:41:03|\n",
            "|2013-01-01|     RIO DE JANEIRO|ÓLEO DIESEL S-10 ...|  m3|71139.00099999999|2021-06-24 00:41:03|\n",
            "|2013-01-01|          SÃO PAULO|ÓLEO DIESEL S-10 ...|  m3|        151757.57|2021-06-24 00:41:03|\n",
            "+----------+-------------------+--------------------+----+-----------------+-------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryhoHkhCZRnA"
      },
      "source": [
        "#### Check if totals match raw data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSICLgpNeVGC"
      },
      "source": [
        "import random\n",
        "\n",
        "def rnd_query(df_raw, table_name):\n",
        "  \"\"\"\n",
        "  Creates a random query to extract the sum of the column volume that matches a random year, product and UF. \n",
        "  Also return the matching total column value from the original raw data.\n",
        "\n",
        "  :param pd.DataFrame df: diesel-by-uf-and-type.csv or oil-derivative-fuels-by-uf-and-product.csv derivate Pandas dataframe\n",
        "  :param string table_name: Name of the refined Spark dataframe derived table from raw data\n",
        "\n",
        "  :returns: SUM Query for random parameters with expected total column value from raw data\n",
        "  \"\"\"\n",
        "\n",
        "  # Select random values for UF, Product and Year with corresponding Total value from Pandas raw Dataframe\n",
        "\n",
        "  rnd_uf = str(random.choice(df_raw.iloc[:,3].unique()))\n",
        "  rnd_product = str(random.choice(df_raw.iloc[:,0].unique()))\n",
        "  rnd_year = random.choice(df_raw.iloc[:,1].unique())\n",
        "\n",
        "  error = True\n",
        "  while error: # Check if the total value exist for rnd_product\n",
        "    try:\n",
        "       rnd_total = df_raw.loc[(df_raw.iloc[:,1]==rnd_year) \\\n",
        "               & (df_raw.iloc[:,3]==rnd_uf) \\\n",
        "               & (df_raw.iloc[:,0]==rnd_product)].iloc[0,-1]\n",
        "       error = False\n",
        "    except:\n",
        "      rnd_product = str(random.choice(df_raw.iloc[:,0].unique()))\n",
        " \n",
        "  print('Random UF: ',rnd_uf)\n",
        "  print('Random Product:',rnd_product)\n",
        "  print('Random Year: ',rnd_year)\n",
        "  print('Expected Total: ', rnd_total)\n",
        "\n",
        "  query = (\"SELECT SUM(volume) FROM {table_name} \\\n",
        "          WHERE uf == '{rnd_uf}' AND \\\n",
        "          YEAR(year_month) == {rnd_year} AND \\\n",
        "          product == '{rnd_product}'\").format(table_name=table_name, rnd_uf=rnd_uf, rnd_year=rnd_year, rnd_product=rnd_product)\n",
        "\n",
        "  return query, rnd_total"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArWFOk78o-ng"
      },
      "source": [
        "# Creates or replaces a local temporary view with selected DataFrame\n",
        "\n",
        "spark_df_diesel.createOrReplaceTempView('diesel')\n",
        "\n",
        "spark_df_oil.createOrReplaceTempView('oil')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZcrRKXSPWFr"
      },
      "source": [
        "def verify_match(df_raw, table_name):\n",
        "  \"\"\"\n",
        "  Verifies if the SUM of volume column from table using random parameters matches the corresponding total in the original data.\n",
        "  Raise error if it doesn't.\n",
        "\n",
        "  :param pd.DataFrame df: diesel-by-uf-and-type.csv or oil-derivative-fuels-by-uf-and-product.csv derivate Pandas dataframe\n",
        "  :param string table_name: Name of the refined Spark dataframe derived table from raw data\n",
        "  \"\"\"\n",
        "  print('--------------------------------------------------')\n",
        "  \n",
        "  print('Table being verified: ',table_name,'\\n')\n",
        "  print('Query SUM result must match the expected random Total:\\n')\n",
        "\n",
        "  query, rnd_total = rnd_query(df_raw, table_name)\n",
        "  \n",
        "  results = spark.sql(query)\n",
        "\n",
        "  print('\\nQuery result from {table_name} table:'.format(table_name=table_name))\n",
        "  results.show()\n",
        "\n",
        "  if abs(results.head()[0] - rnd_total) <0.01: # Discard differences of small decimal digits\n",
        "    print('Total values match')\n",
        "\n",
        "  else:\n",
        "    raise ValueError('Verify data consistency')\n",
        "\n",
        "  print('--------------------------------------------------')\n",
        "\n",
        "  pass"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7H0GoafPsjM",
        "outputId": "0fa76848-7ac8-4a69-9877-dd7e31b77576"
      },
      "source": [
        "# Run verify_match function to validade refined data with raw totals\n",
        "\n",
        "verify_match(df_diesel_raw, 'diesel')\n",
        "\n",
        "verify_match(df_oil_raw, 'oil')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Table being verified:  diesel \n",
            "\n",
            "Query SUM result must match the expected random Total:\n",
            "\n",
            "Random UF:  RIO DE JANEIRO\n",
            "Random Product: ÓLEO DIESEL MARÍTIMO (m3)\n",
            "Random Year:  2019\n",
            "Expected Total:  243919.34699999998\n",
            "\n",
            "Query result from diesel table:\n",
            "+-----------+\n",
            "|sum(volume)|\n",
            "+-----------+\n",
            "| 243919.347|\n",
            "+-----------+\n",
            "\n",
            "Total values match\n",
            "--------------------------------------------------\n",
            "--------------------------------------------------\n",
            "Table being verified:  oil \n",
            "\n",
            "Query SUM result must match the expected random Total:\n",
            "\n",
            "Random UF:  MARANHÃO\n",
            "Random Product: ÓLEO DIESEL (m3)\n",
            "Random Year:  2013\n",
            "Expected Total:  1214221.924\n",
            "\n",
            "Query result from oil table:\n",
            "+-----------+\n",
            "|sum(volume)|\n",
            "+-----------+\n",
            "|1214221.924|\n",
            "+-----------+\n",
            "\n",
            "Total values match\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZQc0BmdSFaN"
      },
      "source": [
        "## Verifying results but now with both tables concatenated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KaK7jZyToP1",
        "outputId": "4fb587da-3a78-4f8d-9c74-cca61ae38ddc"
      },
      "source": [
        "# Concatenate raw dfs created earlier with Pandas\n",
        "\n",
        "df_concat_raw = pd.concat([df_oil_raw, df_diesel_raw], axis=0)\n",
        "\n",
        "df_concat = translate_setdate(df_concat_raw)\n",
        "\n",
        "print('df_concat columns: ',list(df_concat.columns))\n",
        "print('df_concat row count: ',len(df_concat.index))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_concat columns:  ['year_month', 'uf', 'product', 'unit', 'volume']\n",
            "df_concat row count:  67392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksh39AoJV9jM",
        "outputId": "9764e1c6-2ee4-4e5f-e14b-719ae16754a5"
      },
      "source": [
        "# Creates Spark Dataframes with required schema and timestamp column\n",
        "\n",
        "spark_df_concat = spark.createDataFrame(df_concat, schema=schema) \\\n",
        "  .withColumn('created_at', unix_timestamp(lit(datetime.datetime.fromtimestamp(time.time()) \\\n",
        "  .strftime('%Y-%m-%d %H:%M:%S')),'yyyy-MM-dd HH:mm:ss') \\\n",
        "  .cast(\"timestamp\"))\n",
        "\n",
        "print('spark_df_concat schema:')\n",
        "spark_df_concat.printSchema()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spark_df_concat schema:\n",
            "root\n",
            " |-- year_month: date (nullable = false)\n",
            " |-- uf: string (nullable = false)\n",
            " |-- product: string (nullable = false)\n",
            " |-- unit: string (nullable = false)\n",
            " |-- volume: double (nullable = true)\n",
            " |-- created_at: timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQAyDrauW6l-",
        "outputId": "a5fb9e71-8b71-4e6c-adbc-1a5597bad7b6"
      },
      "source": [
        "# Creates or replaces a local temporary view with selected DataFrame\n",
        "spark_df_concat.createOrReplaceTempView('concat')\n",
        "\n",
        "# Run verify_match function to validade refined data with raw totals\n",
        "verify_match(df_concat_raw, 'concat')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Table being verified:  concat \n",
            "\n",
            "Query SUM result must match the expected random Total:\n",
            "\n",
            "Random UF:  ACRE\n",
            "Random Product: ÓLEO DIESEL S-10 (m3)\n",
            "Random Year:  2018\n",
            "Expected Total:  38150.815\n",
            "\n",
            "Query result from concat table:\n",
            "+-----------+\n",
            "|sum(volume)|\n",
            "+-----------+\n",
            "|  38150.815|\n",
            "+-----------+\n",
            "\n",
            "Total values match\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChU3C6sNdbzu"
      },
      "source": [
        "## Exporting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e0OsTj_aV8O"
      },
      "source": [
        "# Save dataframes as compressed .csv.gz in the refined_data folder\n",
        "\n",
        "spark_df_oil.coalesce(1).write \\\n",
        "                .option('header', 'true') \\\n",
        "                .csv('refined_data/oil_derivative_fuels_by_uf_and_product_refined_data', mode='overwrite', sep=';', compression='gzip', encoding='iso-8859-1')\n",
        "\n",
        "spark_df_diesel.coalesce(1).write \\\n",
        "                .option('header', 'true') \\\n",
        "                .csv('refined_data/diesel_by_uf_and_type_refined_data', mode='overwrite', sep=';', compression='gzip', encoding='iso-8859-1')\n",
        "\n",
        "spark_df_concat.coalesce(1).write \\\n",
        "                .option('header', 'true') \\\n",
        "                .csv('refined_data/oil_and_diesel_refined_data', mode='overwrite', sep=';', compression='gzip', encoding='iso-8859-1')"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}